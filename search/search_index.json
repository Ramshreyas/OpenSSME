{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"OpenSSME","text":"<p>OpenSSME (Open Source Small Model Expert) is a lightweight, extensible framework designed to be the \"factory\" for creating Small Expert Models (SEMs).</p> <p>In a world dominated by massive General Purpose LLMs, OpenSSME empowers developers to build specialized, efficient, and domain-specific models that run faster and cheaper.</p>"},{"location":"#core-philosophy","title":"Core Philosophy","text":"<ul> <li>Lightweight: Minimal dependencies, easy to install, and runs on standard hardware.</li> <li>Extensible: Built on the Strategy Pattern, allowing you to swap out every component (Data Synthesis, Training, Evaluation) with your own custom logic.</li> <li>Pipeline-Driven: A clear, three-stage process to go from raw data to a deployed expert model.</li> </ul>"},{"location":"#the-pipeline","title":"The Pipeline","text":"<p>OpenSSME divides the model creation process into three distinct stages:</p> <ol> <li> <p>Data Forge (Current Focus):</p> <ul> <li>Ingest raw data (PDFs, Text, Markdown).</li> <li>Synthesize high-quality instruction-tuning datasets using a \"Teacher\" LLM (e.g., Gemini, GPT-4).</li> <li>Format data for training.</li> </ul> </li> <li> <p>Training Floor (Coming Soon):</p> <ul> <li>Fine-tune small base models (e.g., Llama-3-8B, Gemma-2B) on your synthesized data.</li> <li>Support for LoRA and QLoRA for efficient training.</li> </ul> </li> <li> <p>Evaluation Arena (Coming Soon):</p> <ul> <li>Benchmark your expert model against the Teacher model.</li> <li>Generate reports on accuracy, hallucination rate, and domain specificity.</li> </ul> </li> </ol>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to build your first model? Jump straight into the action:</p> <p>\ud83d\ude80 Go to Quick Start Guide</p>"},{"location":"architecture/","title":"Architecture","text":"<p>OpenSSME is designed to be modular. Understanding the project structure and the underlying design patterns will help you get the most out of the framework.</p>"},{"location":"architecture/#project-structure","title":"Project Structure","text":"<p>When you initialize an OpenSSME workspace, you get a standard structure:</p> <pre><code>openssme_workspace/\n\u251c\u2500\u2500 opensem.py              # The CLI entry point\n\u251c\u2500\u2500 configs/                # Configuration files for your projects\n\u2502   \u2514\u2500\u2500 my_project/\n\u2502       \u251c\u2500\u2500 data_config.yaml   # Config for Data Forge\n\u2502       \u2514\u2500\u2500 train_config.yaml  # Config for Training (Future)\n\u251c\u2500\u2500 data/                   # Data storage\n\u2502   \u2514\u2500\u2500 my_project/\n\u2502       \u251c\u2500\u2500 raw/            # Your input files (PDFs, txt)\n\u2502       \u251c\u2500\u2500 processed/      # Synthesized JSONL files\n\u2502       \u2514\u2500\u2500 golden/         # Golden test sets\n\u251c\u2500\u2500 src/                    # Source code\n\u2502   \u2514\u2500\u2500 opensem/            # Core library\n\u2514\u2500\u2500 models/                 # Saved model adapters\n</code></pre>"},{"location":"architecture/#the-strategy-pattern","title":"The Strategy Pattern","text":"<p>The heart of OpenSSME's extensibility is the Strategy Pattern. We define abstract base classes (Interfaces) for key components, and you can provide your own implementations.</p>"},{"location":"architecture/#the-baseforge-interface","title":"The <code>BaseForge</code> Interface","text":"<p>For the Data Forge stage, everything inherits from <code>BaseForge</code>.</p> <pre><code>class BaseForge(ABC):\n    @abstractmethod\n    def load_data(self) -&gt; List[str]:\n        pass\n\n    @abstractmethod\n    def synthesize(self, raw_data: List[str]) -&gt; List[Dict[str, Any]]:\n        pass\n\n    @abstractmethod\n    def format_data(self, synthesized_data: List[Dict[str, Any]]) -&gt; None:\n        pass\n</code></pre> <ul> <li>Default Implementation: <code>TextForge</code> is the default strategy. It loads text/PDFs and uses an LLM to synthesize instruction pairs.</li> <li>Custom Implementation: You can write a <code>PIIMaskingForge</code>, <code>ImageCaptioningForge</code>, or <code>FinancialForecastingForge</code> by simply inheriting from <code>BaseForge</code> and implementing these three methods.</li> </ul> <p>You then tell OpenSSME which strategy to use in your <code>data_config.yaml</code>:</p> <pre><code>forge_class: \"my_custom_module.MyForge\"\n</code></pre>"},{"location":"notebooks/","title":"Interactive Notebooks","text":"<p>The best way to learn is by doing. We have prepared Jupyter Notebooks that allow you to experiment with the OpenSSME API directly.</p>"},{"location":"notebooks/#available-notebooks","title":"Available Notebooks","text":""},{"location":"notebooks/#1-data-forge-tutorial","title":"1. Data Forge Tutorial","text":"<p>Location: <code>notebooks/data_forge_tutorial.ipynb</code></p> <p>This notebook covers: *   Setup: Importing OpenSSME libraries. *   Standard Pipeline: Running <code>TextForge</code> to synthesize data from text. *   Custom Extension: Implementing a <code>PIIMaskingForge</code> to redact names from text using an LLM, demonstrating how to extend the framework for custom tasks. *   Deployment: How to take your notebook code and deploy it to the CLI.</p> <p>To run these notebooks, ensure you have installed the development dependencies:</p> <pre><code>pip install ipykernel\n</code></pre>"},{"location":"tutorials/data_forge/","title":"Data Forge Tutorial","text":"<p>The Data Forge is the first stage of the OpenSSME pipeline. Its job is to transform raw, unstructured data into high-quality, structured training data (Instruction-Input-Output pairs).</p>"},{"location":"tutorials/data_forge/#standard-flow-text-synthesis","title":"Standard Flow: Text Synthesis","text":"<p>By default, OpenSSME uses the <code>TextForge</code> strategy.</p> <ol> <li>Input: Text files, Markdown files, or PDFs in <code>data/&lt;project&gt;/raw</code>.</li> <li>Process:<ul> <li>Chunks the text.</li> <li>Sends chunks to a \"Teacher\" LLM (Gemini 2.0 Flash).</li> <li>Prompts the Teacher to generate instruction-response pairs based on the text.</li> </ul> </li> <li>Output: A JSONL file in <code>data/&lt;project&gt;/processed/train.jsonl</code>.</li> </ol>"},{"location":"tutorials/data_forge/#configuration","title":"Configuration","text":"<p>You can control this behavior in <code>configs/&lt;project&gt;/data_config.yaml</code>:</p> <pre><code>forge_class: \"opensem.forge.text_forge.TextForge\"\nparams:\n  teacher_model: \"gemini-2.0-flash\"\n  max_chars_per_doc: 10000\n  chunk_size: 2000\n</code></pre>"},{"location":"tutorials/data_forge/#advanced-flow-custom-strategies","title":"Advanced Flow: Custom Strategies","text":"<p>OpenSSME shines when you need to do something specific. Let's say you want to build a model that redacts PII (Personally Identifiable Information). You don't just want generic synthesis; you want a specific transformation.</p>"},{"location":"tutorials/data_forge/#1-create-a-custom-forge-class","title":"1. Create a Custom Forge Class","text":"<p>Create a python file <code>src/my_project/pii_forge.py</code>:</p> <pre><code>from opensem.forge import TextForge\nimport google.generativeai as genai\nimport os\n\nclass PIIMaskingForge(TextForge):\n    def synthesize(self, raw_data):\n        # Custom logic to ask LLM to redact names\n        model = genai.GenerativeModel('gemini-2.0-flash')\n        results = []\n        for doc in raw_data:\n            prompt = f\"Redact all names in this text: {doc}\"\n            response = model.generate_content(prompt)\n            results.append({\n                \"instruction\": \"Redact PII\",\n                \"input\": doc,\n                \"output\": response.text\n            })\n        return results\n</code></pre>"},{"location":"tutorials/data_forge/#2-update-configuration","title":"2. Update Configuration","text":"<p>Point your project to this new class in <code>configs/&lt;project&gt;/data_config.yaml</code>:</p> <pre><code>forge_class: \"my_project.pii_forge.PIIMaskingForge\"\n</code></pre>"},{"location":"tutorials/data_forge/#3-run","title":"3. Run","text":"<pre><code>python opensem.py run-forge --project &lt;project&gt;\n</code></pre> <p>OpenSEM will now load your custom class and execute your specific logic!</p>"},{"location":"tutorials/quick_start/","title":"Quick Start Guide","text":"<p>This guide will get you up and running with OpenSEM in minutes.</p>"},{"location":"tutorials/quick_start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>Conda (Miniconda or Anaconda)</li> <li>A Google Gemini API Key (for the default Data Forge strategy)</li> </ul>"},{"location":"tutorials/quick_start/#installation","title":"Installation","text":"<ol> <li> <p>Clone the Repository (or download the source):     <code>bash     git clone https://github.com/Ramshreyas/OpenSSME.git     cd OpenSSME</code></p> </li> <li> <p>Initialize Workspace &amp; Environment:     Run the initialization command. This will create the necessary directory structure and set up a Conda environment named <code>opensem</code> with all dependencies installed.     <code>bash     python opensem.py init</code></p> </li> <li> <p>Activate the Environment:     <code>bash     conda activate opensem</code></p> </li> <li> <p>Set up Environment Variables:     Create a <code>.env</code> file in the root directory and add your API key:     <code>bash     GEMINI_API_KEY=your_api_key_here</code></p> </li> </ol>"},{"location":"tutorials/quick_start/#usage","title":"Usage","text":"<p>All commands are run via the <code>opensem.py</code> CLI tool.</p>"},{"location":"tutorials/quick_start/#1-initialize-workspace","title":"1. Initialize Workspace","text":"<p>(If you skipped step 2 above)</p> <pre><code>python opensem.py init\n</code></pre>"},{"location":"tutorials/quick_start/#2-create-a-new-project","title":"2. Create a New Project","text":"<p>Create a container for your specific model task. Let's call it <code>testsem</code>.</p> <pre><code>python opensem.py new testsem\n</code></pre> <p>This creates: *   <code>configs/testsem/data_config.yaml</code> *   <code>data/testsem/raw/</code> *   <code>data/testsem/processed/</code></p>"},{"location":"tutorials/quick_start/#3-add-data","title":"3. Add Data","text":"<p>Place your raw documents (PDF, txt, md) into the project.</p> <pre><code># You can manually copy files or use the helper command (coming soon)\ncp my_document.pdf data/testsem/raw/\n</code></pre>"},{"location":"tutorials/quick_start/#4-run-the-data-forge","title":"4. Run the Data Forge","text":"<p>Synthesize training data from your raw documents.</p> <pre><code>python opensem.py run-forge --project testsem\n</code></pre> <p>Check the output in <code>data/testsem/processed/train.jsonl</code>.</p>"}]}